\documentclass[12pt,a4paper]{article} 

\usepackage{float,times,graphicx,mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{pdfpages}
\usepackage{natbib}
\usepackage[space]{grffile}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{url}
\usepackage{bbm}
\usepackage{tikzsymbols}

\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\tr}{tr}
\bibpunct[, ]{(}{)}{;}{a}{,}{,}
\graphicspath{{../Burkina Faso/12/}}  
\addtolength{\oddsidemargin}{-1in}
	\addtolength{\evensidemargin}{-1in}
	\addtolength{\textwidth}{1.75in}
	\addtolength{\topmargin}{-1.3in}
	\addtolength{\textheight}{2in}
\date{\vspace{-5ex}}

\begin{document}
Prior for spline coefficients $\boldsymbol{\beta} \sim \sqrt{\tau^{-1}} AR2(2\rho, -\rho), \quad \rho \in (0, 1)$, where $AR2$ is standardised with marginal variances $= 1.$

\paragraph{PC priors for $\rho$} \\~\\

Assuming $\boldsymbol{\beta}$ follows an AR2 process with $\boldsymbol{\rho} = (2\rho, -\rho)$, with $\rho \in (0, 1)$ and let $\boldsymbol{\Sigma}$ be the corresponding correlation matrix, i.e. marginal variances of $\boldsymbol{\beta} = 1$. Then the KLD for the construction of the PC prior for $\rho$, assuming base model is $\rho = 0$ (i.e. an i.i.d Normal), is:

\begin{align*}
KLD(f_1 \Vert f_0) = -\frac{1}{2} \Bigg( \text{tr}(\boldsymbol{\Sigma_0^{-1} \Sigma_1}) - n - \log \Big( \frac{\vert  \boldsymbol{\Sigma_1} \vert}{\vert \boldsymbol{\Sigma_0} \vert} \Big) \Bigg)
\end{align*}
Since the base model is $\rho = 0$, $\boldsymbol{\Sigma_0} = \boldsymbol{I}$ and hence $\text{tr}(\boldsymbol{\Sigma_0^{-1}\Sigma_1}) = \text{tr}(\boldsymbol{\Sigma_1}) = n$, since $\boldsymbol{\Sigma_1}$ is a correlation matrix.

\begin{align*}
\implies KLD(f_1 \Vert f_0) &= -\frac{1}{2} \log(\vert \boldsymbol{\Sigma_1} \vert) \\
&= -\frac{1}{2} \log \big[ \, (1-\psi_1^2)^{n-1} (1-\psi_2^2)^{n-2} \, \big] \\
&= -\frac{1}{2} \log \big[ \, (1- \big(\frac{2\rho}{1+\rho}\big)^2 )^{n-1} (1-\rho^2)^{n-2}\, \big] \\
&= -\frac{1}{2} \log \big[\, (1+3\rho)^{n-1} (1-\rho)^{2n-3} (1+\rho)^{-n}  \, \big]
\end{align*}


The PC prior is defined as an exponential prior on $d(\rho) = \sqrt{2 KLD(f_1 \Vert f_0)}$ with rate $\lambda$.

Consider 
\begin{align*}
d(\rho) &= \sqrt{2 KLD(f_1 \Vert f_0)} \\
&= \sqrt{- \log \big[ \, (1- \big(\frac{2\rho}{1+\rho}\big)^2 )^{n-1} (1-\rho^2)^{n-2}\, \big]} \tag{1}\\
&= \sqrt{(1-n) \log(1+3\rho) + (3-2n) \log(1-\rho) + n \log(1+\rho)}\\
&= \sqrt{f(\rho)},
\end{align*}
then 
\begin{align*}
\frac{\partial d(\rho)}{\partial\rho} &= \frac{1}{2\sqrt{f(\rho)}} \Big[\, \frac{3-3n}{1+3\rho} + \frac{2n-3}{1-\rho} + \frac{n}{1+\rho} \,\Big] \\
&= \frac{1}{2\sqrt{f(\rho)}} \Big[\, \frac{(3-3n)(1-\rho)(1+\rho) + (2n-3)(1+3\rho)(1+\rho) + n(1+3\rho)(1-\rho)}{(1+3\rho)(1-\rho)(1+\rho)}   \,\Big] \\
&= \frac{1}{2\sqrt{f(\rho)}} \Big[\, \frac{\rho^2(6n-12) + \rho(10n - 12)}{(1+3\rho)(1-\rho)(1+\rho)}\,\Big] > 0 \qquad \qquad \forall \rho \in (0, 1),
\end{align*}
i.e. $d(\rho)$ is a monotonically increasing positive function in $\rho$, which is intuitive as $\rho \to 1$ means higher deviation from the base model $\rho = 0$ and hence higher KLD. 

Thus, PC prior for $\rho$ is
\begin{align*}
\pi(\rho) &= \pi_{d}(d(\rho)) \Big \vert \frac{\partial d(\rho)}{\partial\rho} \Big \vert \\
&= \lambda_{\rho} e^{-\lambda_{\rho} d(\rho)} \, \frac{\partial d(\rho)}{\partial \rho}
\end{align*}

To determine the decay rate $\lambda_{\rho}$, the authors suggested inferring from a interpretable probability statement $P(Q(\rho) > U) = \alpha$ for some $\alpha$ as the tail probability. Here I plan to directly work on the $\rho$ scale, e.g. specifying $P(\rho > 0.999) = 0.01$ as a loose PC prior. Since $d(\rho)$ is a monotonically increasing one-to-one mapping, the upper bound specified on $\rho$ can be translated into an upper for $d(\rho)$ as $P(d(\rho) > d(U)) = 0.01$. Knowing the tail probability of an exponential R.V $P(X > x) = 1 - \text{c.d.f}(x) = e^{-\lambda x}$, $\lambda_\rho$ can be derived from $e^{-\lambda_{\rho} d(U)} = 0.01 \implies \lambda_\rho = -\log(0.01) / d(U)$.

\paragraph{PC prior for $\tau$} \\~\\

If information is available on the variability on the spline coefficients, the PC prior for $\tau$ can be inferred directly by a similar procedure of setting an upper bound for $\tau$, however the scale of $\tau$ often depends on several factors, e.g. the spacing of the knots, the scale of the problem, etc. To see this, consider $y = \boldsymbol{B\beta}$ where $\boldsymbol{B}$ is the design matrix, then $\text{VAR}(y) = \tau^{-1}\boldsymbol{B \Sigma_1(\rho) B'}$. Therefore the scale of $\tau$ depends on $\rho$. The diagonal of the matrix $\boldsymbol{B \Sigma_1(\rho) B'}$ is relatively uniform, due to the stationarity of the AR2 process assumed and the equal knot spacing and even data. To simplify the construction, we approximate the marginal variance of each $y_i = \text{VAR}(y_1) = \tau^{-1} \boldsymbol{B_{1\cdot}\phantom{'} \, \Sigma_1{(\rho)} \, B'_{1\cdot}}$, where $\boldsymbol{B_{1\cdot}\phantom{'}}$ is the first row of the design matrix. It is usually easier to give probability statements on the standard deviation of $\boldsymbol{y}$ instead of $\boldsymbol{\beta}$. Hence, the PC prior for $\tau$ is the type-2 Gumbel prior with decay rate $\lambda_{\tau} = -\log(0.01) \sqrt{\text{VAR}(y_1)}/ U_{y}$, where $U_y$ is an upper bound of the standard deviation of $y$.

Therefore
\begin{align*}
f(\tau, \rho) &= f(\tau | \rho) f(\rho) \\
&= \text{type-2 Gumbel}(\tau, \lambda_{\tau}|\rho) \cdot \pi(\rho) \\
&= \text{type-2 Gumbel}(\tau, \lambda_{\tau}|\rho) \cdot  \lambda_{\rho} e^{-\lambda_{\rho} d(\rho)} \, \frac{\partial d(\rho)}{\partial \rho}
\end{align*}

The dependence of $\lambda_{\tau}$ on $\rho$ is through $\text{VAR}(y_1)$.
\end{document}